# MindQuest LLM Configuration
# Copy this file to .env and fill in your actual API keys

# Google Gemini API Key (get from https://aistudio.google.com/apikey)
# Recommended: Use GOOGLE_API_KEY (official SDK standard)
GOOGLE_API_KEY=your_gemini_api_key_here


# Local LLM Configuration (for future Ollama/LM Studio support)
# LOCAL_LLM_ENDPOINT=http://localhost:1234/v1
# LOCAL_LLM_MODEL=model

# Default provider to use ("gemini", "mock", or "local" in the future)
DEFAULT_LLM_PROVIDER=gemini
